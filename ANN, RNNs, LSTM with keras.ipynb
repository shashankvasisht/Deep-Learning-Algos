{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras ##can use import tensorflow.contrib.keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Dropout,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(base_dir, kind):\n",
    "    \"\"\"\n",
    "    kind -  ANN / LSTM\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import os\n",
    "    data = np.load(os.path.join(base_dir, \"%s.npz\"%kind))\n",
    "    train_x, train_y = data[\"train_x\"], data[\"train_y\"]\n",
    "    val_x, val_y = data[\"val_x\"], data[\"val_y\"]\n",
    "    return train_x, train_y, val_x, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x,train_y,val_x,val_y = load_data('/home/shashank/Desktop/BootcampStudents/Data/Task_1/','ANN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(588, 102400)\n"
     ]
    }
   ],
   "source": [
    "print train_x.shape  ### 588 datapoints (rows) having 50*2048 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dense input = 102400, neurons = 128\n",
    "#batchnormalisation\n",
    "#leaky relu\n",
    "#Dropout\n",
    "#Dense Softmax neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()                                      #dense input = 102400 , neurons=128\n",
    "model.add(Dense(128,input_dim =102400)) \n",
    "                                                        #basically architecture of the NN\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 128)               13107328  \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 13,108,485\n",
      "Trainable params: 13,108,229\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 588 samples, validate on 58 samples\n",
      "Epoch 1/10\n",
      "588/588 [==============================] - 55s - loss: 0.5163 - acc: 0.7993 - val_loss: 3.4088 - val_acc: 0.5345\n",
      "Epoch 2/10\n",
      "588/588 [==============================] - 8s - loss: 0.1989 - acc: 0.9388 - val_loss: 1.4273 - val_acc: 0.5172\n",
      "Epoch 3/10\n",
      "588/588 [==============================] - 6s - loss: 0.1419 - acc: 0.9558 - val_loss: 0.6799 - val_acc: 0.8103\n",
      "Epoch 4/10\n",
      "588/588 [==============================] - 6s - loss: 0.0973 - acc: 0.9847 - val_loss: 0.5327 - val_acc: 0.8448\n",
      "Epoch 5/10\n",
      "588/588 [==============================] - 6s - loss: 0.0747 - acc: 0.9830 - val_loss: 0.5066 - val_acc: 0.8276\n",
      "Epoch 6/10\n",
      "588/588 [==============================] - 6s - loss: 0.0445 - acc: 0.9966 - val_loss: 0.3698 - val_acc: 0.8448\n",
      "Epoch 7/10\n",
      "588/588 [==============================] - 6s - loss: 0.0349 - acc: 0.9966 - val_loss: 0.3166 - val_acc: 0.8793\n",
      "Epoch 8/10\n",
      "588/588 [==============================] - 6s - loss: 0.0322 - acc: 0.9983 - val_loss: 0.3145 - val_acc: 0.8276\n",
      "Epoch 9/10\n",
      "588/588 [==============================] - 6s - loss: 0.0231 - acc: 1.0000 - val_loss: 0.3445 - val_acc: 0.8103\n",
      "Epoch 10/10\n",
      "588/588 [==============================] - 6s - loss: 0.0154 - acc: 1.0000 - val_loss: 0.3239 - val_acc: 0.8621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0084259bd0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x,train_y,validation_data=(val_x,val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RNN input = (50,2048) --->50 frames---->each frame has 2048 features , Neurons = 128\n",
    "# Dropout\n",
    "# BatchNorm\n",
    "# Leaky Relu\n",
    "# Dense Softmax Activation neurons = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1_x,train1_y,val1_x,val1_y = load_data('/home/shashank/Desktop/BootcampStudents/Data/Task_1/','LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(588, 50, 2048)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = Sequential() \n",
    "\n",
    "model1.add(keras.layers.SimpleRNN(128,input_shape = (50,2048)))  #this already has a tanh activation\n",
    "model1.add(keras.layers.BatchNormalization())\n",
    "model1.add(keras.layers.Dropout(0.3))\n",
    "model1.add(Dense(5))\n",
    "model1.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 588 samples, validate on 58 samples\n",
      "Epoch 1/10\n",
      "588/588 [==============================] - 3s - loss: 0.8828 - acc: 0.6599 - val_loss: 0.8893 - val_acc: 0.6207\n",
      "Epoch 2/10\n",
      "588/588 [==============================] - 2s - loss: 0.5120 - acc: 0.8367 - val_loss: 0.8002 - val_acc: 0.6379\n",
      "Epoch 3/10\n",
      "588/588 [==============================] - 2s - loss: 0.3617 - acc: 0.8895 - val_loss: 0.5858 - val_acc: 0.7414\n",
      "Epoch 4/10\n",
      "588/588 [==============================] - 2s - loss: 0.3114 - acc: 0.9286 - val_loss: 0.5541 - val_acc: 0.7241\n",
      "Epoch 5/10\n",
      "588/588 [==============================] - 2s - loss: 0.2184 - acc: 0.9541 - val_loss: 0.5865 - val_acc: 0.7759\n",
      "Epoch 6/10\n",
      "588/588 [==============================] - 2s - loss: 0.2113 - acc: 0.9524 - val_loss: 0.5980 - val_acc: 0.7414\n",
      "Epoch 7/10\n",
      "588/588 [==============================] - 2s - loss: 0.1826 - acc: 0.9592 - val_loss: 0.4300 - val_acc: 0.8448\n",
      "Epoch 8/10\n",
      "588/588 [==============================] - 2s - loss: 0.1760 - acc: 0.9609 - val_loss: 0.4334 - val_acc: 0.7931\n",
      "Epoch 9/10\n",
      "588/588 [==============================] - 2s - loss: 0.1622 - acc: 0.9609 - val_loss: 0.4272 - val_acc: 0.8276\n",
      "Epoch 10/10\n",
      "588/588 [==============================] - 2s - loss: 0.1241 - acc: 0.9796 - val_loss: 0.4207 - val_acc: 0.8103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f33ec11a2d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(train1_x,train1_y,validation_data=(val1_x,val1_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = Sequential() \n",
    "\n",
    "model1.add(keras.layers.LSTM(128,input_shape = (50,2048)))  #this already has a tanh activation\n",
    "model1.add(keras.layers.BatchNormalization())\n",
    "model1.add(keras.layers.Dropout(0.3))\n",
    "model1.add(Dense(5))\n",
    "model1.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.compile(keras.optimizers.sgd(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 588 samples, validate on 58 samples\n",
      "Epoch 1/10\n",
      "588/588 [==============================] - 8s - loss: 0.0413 - acc: 1.0000 - val_loss: 0.5677 - val_acc: 0.7586\n",
      "Epoch 2/10\n",
      "588/588 [==============================] - 7s - loss: 0.0401 - acc: 1.0000 - val_loss: 0.5661 - val_acc: 0.7414\n",
      "Epoch 3/10\n",
      "588/588 [==============================] - 7s - loss: 0.0357 - acc: 0.9983 - val_loss: 0.5674 - val_acc: 0.7586\n",
      "Epoch 4/10\n",
      "588/588 [==============================] - 7s - loss: 0.0354 - acc: 0.9983 - val_loss: 0.5684 - val_acc: 0.7586\n",
      "Epoch 5/10\n",
      "588/588 [==============================] - 7s - loss: 0.0385 - acc: 0.9983 - val_loss: 0.5702 - val_acc: 0.7586\n",
      "Epoch 6/10\n",
      "588/588 [==============================] - 7s - loss: 0.0297 - acc: 0.9983 - val_loss: 0.5714 - val_acc: 0.7586\n",
      "Epoch 7/10\n",
      "588/588 [==============================] - 7s - loss: 0.0326 - acc: 1.0000 - val_loss: 0.5760 - val_acc: 0.7586\n",
      "Epoch 8/10\n",
      "588/588 [==============================] - 7s - loss: 0.0390 - acc: 0.9983 - val_loss: 0.5785 - val_acc: 0.7586\n",
      "Epoch 9/10\n",
      "588/588 [==============================] - 7s - loss: 0.0375 - acc: 1.0000 - val_loss: 0.5813 - val_acc: 0.7586\n",
      "Epoch 10/10\n",
      "588/588 [==============================] - 7s - loss: 0.0316 - acc: 0.9983 - val_loss: 0.5843 - val_acc: 0.7586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f339458dad0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(train1_x,train1_y,validation_data=(val1_x,val1_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?keras.optimizers.sgd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
